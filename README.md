# Tweets_generation_using_Markov_chains
This repository contains the solution for a text generation task using **Markov Chains**. The goal of this project is to generate coherent text sequences based on patterns learned from a dataset, using the Markov Chain model. 

## Table of Contents
- [Overview](#overview)
- [Installation](#installation)
- [Usage](#usage)
- [Data](#data)
- [License](#license)

## Overview

Text generation is the process of automatically creating meaningful text based on an input dataset. In this project, we utilize **Markov Chains** to generate sequences of text, which rely on probabilistic transitions between states (words or characters) based on a given input text dataset.

The repository also includes the script to download data from Hugging Face and save it locally in CSV format for further processing in the Markov Chain model.


## Installation

To run this project locally, follow the steps below:

1. **Clone the repository**:
    ```bash
    git clone https://github.com/Abdelmanemm/PRODIGY_GA_03.git
    cd PRODIGY_GA_03
    ```
2. **Download the dataset**:
    Run the provided `get_data.py` script to download the dataset:
    ```bash
    python data/get_data.py
    ```

## Usage

To explore and run the Markov Chain model for text generation:

1. Open the `Markov_chain.ipynb` notebook using Jupyter Notebook or Jupyter Lab.
2. Follow the steps in the notebook to train the model and generate text sequences.
   
   The notebook demonstrates how to build a simple Markov Chain model and generate coherent text based on the input dataset.

## Data

The dataset used in this project is downloaded from Hugging Face using the `get_data.py` script. The dataset is not included in the repository due to size limitations but will be saved locally in CSV format after running the script.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
